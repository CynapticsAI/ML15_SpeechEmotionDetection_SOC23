{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dataset Prep","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:31.283725Z","iopub.execute_input":"2023-06-27T03:12:31.284213Z","iopub.status.idle":"2023-06-27T03:12:43.821074Z","shell.execute_reply.started":"2023-06-27T03:12:31.284176Z","shell.execute_reply":"2023-06-27T03:12:43.819521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\nCrema = \"/kaggle/input/cremad/AudioWAV/\"\nTess = \"/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data/\"\nSavee = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:43.824236Z","iopub.execute_input":"2023-06-27T03:12:43.825202Z","iopub.status.idle":"2023-06-27T03:12:43.832754Z","shell.execute_reply.started":"2023-06-27T03:12:43.825162Z","shell.execute_reply":"2023-06-27T03:12:43.830947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ravdess_list = os.listdir(Ravdess)\n\nfiles = []\nemotions = []\n\nfor item in ravdess_list:\n    actor = os.listdir(Ravdess + item)\n    for file in actor:\n        name = file.split('.')[0]\n        parts = name.split('-')\n        emotions.append(int(parts[2]))\n        files.append(Ravdess + item + '/' + file)\n        \nemotion_data = pd.DataFrame(emotions, columns=['Emotions'])\nfiles_data = pd.DataFrame(files, columns=['Files'])\n\nravdess_df = pd.concat([emotion_data, files_data], axis=1)\n\nravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n\nravdess_df","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:43.835045Z","iopub.execute_input":"2023-06-27T03:12:43.835480Z","iopub.status.idle":"2023-06-27T03:12:44.360784Z","shell.execute_reply.started":"2023-06-27T03:12:43.835444Z","shell.execute_reply":"2023-06-27T03:12:44.359205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crema = os.listdir(Crema)\nemotions = []\nfiles = []\n\nfor item in crema:\n    files.append(Crema + item)\n    \n    parts = item.split('_')\n    if parts[2] == 'SAD':\n        emotions.append('sad')\n    elif parts[2] == 'ANG':\n        emotions.append('angry')\n    elif parts[2] == 'DIS':\n        emotions.append('disgust')\n    elif parts[2] == 'FEA':\n        emotions.append('fear')\n    elif parts[2] == 'HAP':\n        emotions.append('happy')\n    elif parts[2] == 'NEU':\n        emotions.append('neutral')\n    else :\n        emotions.append('unknown')\n        \nemotions_data = pd.DataFrame(emotions, columns=['Emotions'])\nfiles_data = pd.DataFrame(files, columns=['Files'])\n\ncrema_df = pd.concat([emotions_data, files_data], axis=1)\n\ncrema_df","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:44.364105Z","iopub.execute_input":"2023-06-27T03:12:44.364538Z","iopub.status.idle":"2023-06-27T03:12:44.711671Z","shell.execute_reply.started":"2023-06-27T03:12:44.364502Z","shell.execute_reply":"2023-06-27T03:12:44.710169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tess = os.listdir(Tess)\n\nemotions = []\nfiles = []\n\nfor item in tess:\n    items = os.listdir(Tess + item)\n    for file in items:\n        part = file.split('.')[0]\n        part = part.split('_')[2]\n        if part == 'ps':\n            emotions.append('surprise')\n        else:\n            emotions.append(part)\n        files.append(Tess + item + '/' + file)\n        \ntess_df = pd.concat([pd.DataFrame(emotions, columns=['Emotions']), pd.DataFrame(files, columns=['Files'])], axis=1)\n\ntess_df","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:44.716067Z","iopub.execute_input":"2023-06-27T03:12:44.716518Z","iopub.status.idle":"2023-06-27T03:12:45.603764Z","shell.execute_reply.started":"2023-06-27T03:12:44.716483Z","shell.execute_reply":"2023-06-27T03:12:45.602065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"savee = os.listdir(Savee)\n\nemotions = []\nfiles = []\n\nfor item in savee:\n    files.append(Savee + item)\n    part = file.split('_')[1]\n    ele = part[:-6]\n    if ele == 'a':\n        emotions.append('angry')\n    elif ele == 'd':\n        emotions.append('disgust')\n    elif ele == 'f':\n        emotions.append('fear')\n    elif ele == 'h':\n        emotions.append('happy')\n    elif ele == 'n':\n        emotions.append('neutral')\n    elif ele == 'sa':\n        emotions.append('sad')\n    else:\n        emotions.append('surprise')\n        \nsavee_df = pd.concat([pd.DataFrame(emotions, columns=['Emotions']), pd.DataFrame(files, columns=['Files'])], axis=1)\nsavee_df","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:45.605445Z","iopub.execute_input":"2023-06-27T03:12:45.606253Z","iopub.status.idle":"2023-06-27T03:12:45.760247Z","shell.execute_reply.started":"2023-06-27T03:12:45.606217Z","shell.execute_reply":"2023-06-27T03:12:45.758975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([ravdess_df, crema_df, tess_df, savee_df], axis = 0)\ndf.to_csv(\"df.csv\",index=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:45.762186Z","iopub.execute_input":"2023-06-27T03:12:45.762947Z","iopub.status.idle":"2023-06-27T03:12:45.859810Z","shell.execute_reply.started":"2023-06-27T03:12:45.762902Z","shell.execute_reply":"2023-06-27T03:12:45.858391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Count of Emotions', size=16)\nsns.countplot(x=df['Emotions'])\nplt.ylabel('Count', size=12)\nplt.xlabel('Emotions', size=12)\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:45.861258Z","iopub.execute_input":"2023-06-27T03:12:45.861577Z","iopub.status.idle":"2023-06-27T03:12:46.233549Z","shell.execute_reply.started":"2023-06-27T03:12:45.861548Z","shell.execute_reply":"2023-06-27T03:12:46.232272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_waveplot(data, sr, emotion):\n    plt.figure(figsize=(10, 3))\n    plt.title('Waveplot for {} emotion'.format(emotion), size=15)\n    librosa.display.waveshow(data, sr=sr)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:46.235359Z","iopub.execute_input":"2023-06-27T03:12:46.236487Z","iopub.status.idle":"2023-06-27T03:12:46.244539Z","shell.execute_reply.started":"2023-06-27T03:12:46.236440Z","shell.execute_reply":"2023-06-27T03:12:46.243087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_spectrogram(data, sr, emotion):\n    X = librosa.stft(data)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(12, 3))\n    plt.title('Spectrogram for {} emotion'.format(emotion), size=15)\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')  \n    plt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:46.246464Z","iopub.execute_input":"2023-06-27T03:12:46.246985Z","iopub.status.idle":"2023-06-27T03:12:46.257653Z","shell.execute_reply.started":"2023-06-27T03:12:46.246938Z","shell.execute_reply":"2023-06-27T03:12:46.256719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_wave_spect(emotion):\n    path = np.array(df.Files[df.Emotions==emotion])[0]\n    data, sampling_rate = librosa.load(path)\n    create_waveplot(data, sampling_rate, emotion)\n    create_spectrogram(data, sampling_rate, emotion)\n    return str(path)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:46.259144Z","iopub.execute_input":"2023-06-27T03:12:46.260793Z","iopub.status.idle":"2023-06-27T03:12:46.272037Z","shell.execute_reply.started":"2023-06-27T03:12:46.260727Z","shell.execute_reply":"2023-06-27T03:12:46.271031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Viewing certain audio spectograms","metadata":{}},{"cell_type":"code","source":"Audio(create_wave_spect('happy'))","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:12:46.273444Z","iopub.execute_input":"2023-06-27T03:12:46.274531Z","iopub.status.idle":"2023-06-27T03:13:02.132115Z","shell.execute_reply.started":"2023-06-27T03:12:46.274497Z","shell.execute_reply":"2023-06-27T03:13:02.130552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Audio(create_wave_spect('disgust'))","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:13:02.134850Z","iopub.execute_input":"2023-06-27T03:13:02.136265Z","iopub.status.idle":"2023-06-27T03:13:03.393102Z","shell.execute_reply.started":"2023-06-27T03:13:02.136199Z","shell.execute_reply":"2023-06-27T03:13:03.391797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"def noise(data):\n    noise_amp = 0.035 * np.random.uniform() * np.amax(data)\n    data = data + noise_amp * np.random.normal(size = data.shape[0])\n    return data\n\ndef stretch(data, rate = 0.8):\n    return librosa.effects.time_stretch(data, rate = rate)\n\ndef shift(data):\n    shift_range = int(np.random.uniform(low = -5, high = 5) * 1000)\n    return np.roll(data, shift_range)\n\ndef pitch(data, sampling_rate, pitch_factor = 0.7):\n    return librosa.effects.pitch_shift(data, sr = sampling_rate, n_steps = pitch_factor)\n\n# taking any example and checking for techniques.\npath = np.array(df.Files)[1]\ndata, sample_rate = librosa.load(path)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:13:03.397731Z","iopub.execute_input":"2023-06-27T03:13:03.398157Z","iopub.status.idle":"2023-06-27T03:13:03.432802Z","shell.execute_reply.started":"2023-06-27T03:13:03.398122Z","shell.execute_reply":"2023-06-27T03:13:03.431356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"def extract_features(data):\n    # ZCR\n    result = np.array([])\n    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n    result = np.hstack((result, zcr)) # stacking horizontally\n\n    # Chroma_stft\n    stft = np.abs(librosa.stft(data))\n    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, chroma_stft)) # stacking horizontally\n\n    # MFCC\n    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mfcc)) # stacking horizontally\n\n    # Root Mean Square Value\n    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n    result = np.hstack((result, rms)) # stacking horizontally\n\n    # MelSpectogram\n    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n    result = np.hstack((result, mel)) # stacking horizontally\n    \n    return result\n\ndef get_features(path):\n    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n    \n    # without augmentation\n    res1 = extract_features(data)\n    result = np.array(res1)\n    \n    # data with noise\n    noise_data = noise(data)\n    res2 = extract_features(noise_data)\n    result = np.vstack((result, res2)) # stacking vertically\n    \n    # data with stretching and pitching\n    new_data = stretch(data)\n    data_stretch_pitch = pitch(new_data, sample_rate)\n    res3 = extract_features(data_stretch_pitch)\n    result = np.vstack((result, res3)) # stacking vertically\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:13:03.434919Z","iopub.execute_input":"2023-06-27T03:13:03.435350Z","iopub.status.idle":"2023-06-27T03:13:03.449421Z","shell.execute_reply.started":"2023-06-27T03:13:03.435316Z","shell.execute_reply":"2023-06-27T03:13:03.448139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, Y = [], []\nfor path, emotion in zip(df.Files, df.Emotions):\n    feature = get_features(path)\n    for item in feature:\n        X.append(item)\n        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n        Y.append(emotion)","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:17:06.523646Z","iopub.execute_input":"2023-06-27T03:17:06.524276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X), len(Y), df.Files.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Features = pd.DataFrame(X)\nFeatures['labels'] = Y\nFeatures.to_csv('features.csv', index=False)\nFeatures.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## Data Prep","metadata":{}},{"cell_type":"code","source":"X = Features.iloc[: ,:-1].values\nY = Features['labels'].values\nencoder = OneHotEncoder()\nY = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n# splitting data\nx_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:16:57.312850Z","iopub.status.idle":"2023-06-27T03:16:57.313344Z","shell.execute_reply.started":"2023-06-27T03:16:57.313112Z","shell.execute_reply":"2023-06-27T03:16:57.313134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.expand_dims(x_train, axis=2)\nx_test = np.expand_dims(x_test, axis=2)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=32, activation='relu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(units=8, activation='softmax'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-27T03:16:57.315477Z","iopub.status.idle":"2023-06-27T03:16:57.315934Z","shell.execute_reply.started":"2023-06-27T03:16:57.315708Z","shell.execute_reply":"2023-06-27T03:16:57.315729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\nhistory=model.fit(x_train, y_train, batch_size=64, epochs=150, validation_data=(x_test, y_test), callbacks=[rlrp, es])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\nepochs = [i for i in range(50)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\ntest_acc = history.history['val_accuracy']\ntest_loss = history.history['val_loss']\nfig.set_size_inches(20,6)\nax[0].plot(epochs , train_loss , label = 'Training Loss')\nax[0].plot(epochs , test_loss , label = 'Testing Loss')\nax[0].set_title('Training & Testing Loss')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[1].plot(epochs , train_acc , label = 'Training Accuracy')\nax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[1].set_title('Training & Testing Accuracy')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}